{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsmfgIagXlts"
   },
   "source": [
    "# Super Mario Bros Gym\n",
    "This is the example notebook for the seminar:\n",
    "\n",
    "392142 Applied Cognitive Computing: Advancing Reinforcement Learning Agents through Cognitive Mechanisms\n",
    "\n",
    "You can change any part of this colab for your group work. Simply go to File -> \"Save a Copy to Drive\" and start changing parts of the code.\n",
    "\n",
    "Please don't use any reinforcement learning libraries for your group work (Stable Baselines, Chainer RL, and so on). The idea is not to simply plug in the state of the art model, but learn what works and what doesn't work by modifying an algorithm.\n",
    "\n",
    "For example, for the group work you could:\n",
    "- Change the reward model\n",
    "- Change the input\n",
    "- Change parts of PPO\n",
    "- Change parts of the environment\n",
    "- Implement a different Reinforcement Learning algorithm\n",
    "- Try out non Reinforcement Learning algorithms (MDP, POMDP, Genetic Algorithms)\n",
    "- Optimize part of the environment\n",
    "- Try out ANY other idea you have that could help in getting mario as far as possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljVkIDl4YfNf"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "! pip install gym==0.24.1 gym-super-mario-bros==7.4.0 nes_py==8.2.1 numpy==1.22.0 torch==2.2.0  torchaudio==2.2.0  torchrl==0.3.0  torchvision==0.17.0  tqdm==4.66.5 matplotlib==3.5.2 scipy==1.11.1 mediapy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwSex1aRZplg"
   },
   "source": [
    "## Checking the gpu that is provided by google colab.\n",
    "If you don't see a gpu listed, or an error is shown, please click on the small dropdown arrow on the top right corner and choose \"View Ressources\" from the appearing menu.\n",
    "\n",
    "From there you can click on \"Change runtime type\" on the bottom right.\n",
    "\n",
    "In the appearing window, you should be able to select a \"Hardware accelerator\", which you will have to set to \"GPU\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 111,
     "status": "ok",
     "timestamp": 1745690826310,
     "user": {
      "displayName": "Bjarne Thomzik",
      "userId": "06928226671254719565"
     },
     "user_tz": -120
    },
    "id": "8oEVD5spYICr",
    "outputId": "d801acb2-7903-477c-80f5-447eb40d777e",
    "ExecuteTime": {
     "end_time": "2025-04-27T23:16:26.908468Z",
     "start_time": "2025-04-27T23:16:26.794773Z"
    }
   },
   "source": [
    "! nvidia-smi"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 28 01:16:26 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.94                 Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2070      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   42C    P8             39W /  112W |    2608MiB /   8192MiB |      1%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1328    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A      2348    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A      4000    C+G   ...rams\\PyCharm\\jbr\\bin\\cef_server.exe      N/A      |\n",
      "|    0   N/A  N/A      4672    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A      4896    C+G   C:\\Windows\\System32\\mmgaserver.exe          N/A      |\n",
      "|    0   N/A  N/A      5380    C+G   ...m Files\\Mozilla Firefox\\firefox.exe      N/A      |\n",
      "|    0   N/A  N/A     10528    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     11408    C+G   ...nzyj5cx40ttqa\\iCloud\\iCloudHome.exe      N/A      |\n",
      "|    0   N/A  N/A     11424    C+G   ...al\\Discord\\app-1.0.9189\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A     12588    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe      N/A      |\n",
      "|    0   N/A  N/A     12792    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     13272    C+G   ...m Files\\Mozilla Firefox\\firefox.exe      N/A      |\n",
      "|    0   N/A  N/A     14348    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     15216    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     15736    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     15744      C   ...nvs\\mario\\python.exe.c~.conda_trash      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odqlWAkUanmT"
   },
   "source": [
    "# PPO Algorithm\n",
    "\n",
    "Here we define the PPO Algorithm, that can be freely extended during the seminar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_y-oupXa4eZ"
   },
   "source": [
    "The imports used for the PPO algorithm"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZZJwF2ddafxt",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745690839044,
     "user_tz": -120,
     "elapsed": 2685,
     "user": {
      "displayName": "Bjarne Thomzik",
      "userId": "06928226671254719565"
     }
    },
    "outputId": "6ed138fc-594f-4086-877b-17f4bb1899a1",
    "ExecuteTime": {
     "end_time": "2025-04-27T23:16:26.954345Z",
     "start_time": "2025-04-27T23:16:26.940385Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import MultivariateNormal\n",
    "from torch.distributions import Categorical\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT,COMPLEX_MOVEMENT\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from gym.wrappers import GrayScaleObservation"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gczdoo9a9mH"
   },
   "source": [
    "Setting the device to gpu if available"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1745690848341,
     "user": {
      "displayName": "Bjarne Thomzik",
      "userId": "06928226671254719565"
     },
     "user_tz": -120
    },
    "id": "AYDdPY8tYY_e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0065c5a9-cd3e-4d0a-d336-43584be1fca4",
    "ExecuteTime": {
     "end_time": "2025-04-27T23:16:27.015183Z",
     "start_time": "2025-04-27T23:16:26.986261Z"
    }
   },
   "source": [
    "# set device to cpu or cuda\n",
    "device = torch.device('cpu')\n",
    "if(torch.cuda.is_available()):\n",
    "    device = torch.device('cuda:0')\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Device set to : \" + str(torch.cuda.get_device_name(device)))\n",
    "\n",
    "else:\n",
    "    print(\"Device set to : cpu\")\n",
    "    device = torch.device(\"cpu\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to : NVIDIA GeForce RTX 2070\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzUoRPJzboly"
   },
   "source": [
    "## ActorCritic\n",
    "Here we define the actor critic agent that functions as our neural network.\n",
    "To get a better understanding of the algorithm you can take a look at: https://theaisummer.com/Actor_critics/"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RolloutBuffer"
   ],
   "metadata": {
    "id": "_QKD_k1SmMwv"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XclKPLRwe-jS",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745690858109,
     "user_tz": -120,
     "elapsed": 43,
     "user": {
      "displayName": "Bjarne Thomzik",
      "userId": "06928226671254719565"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-04-27T23:16:27.076021Z",
     "start_time": "2025-04-27T23:16:27.064053Z"
    }
   },
   "source": [
    "# The RolloutBuffer which keeps the training tuples.\n",
    "class RolloutBuffer:\n",
    "    def __init__(self):\n",
    "        self.actions = []\n",
    "        self.states = []\n",
    "        self.logprobs = []\n",
    "        self.rewards = []\n",
    "        self.is_terminals = []\n",
    "\n",
    "    # We clear the buffer after each training update\n",
    "    def clear(self):\n",
    "        del self.actions[:]\n",
    "        del self.states[:]\n",
    "        del self.logprobs[:]\n",
    "        del self.rewards[:]\n",
    "        del self.is_terminals[:]"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7Wo4XyWjbPve",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745690860081,
     "user_tz": -120,
     "elapsed": 10,
     "user": {
      "displayName": "Bjarne Thomzik",
      "userId": "06928226671254719565"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-04-27T23:16:27.152815Z",
     "start_time": "2025-04-27T23:16:27.123892Z"
    }
   },
   "source": [
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, has_continuous_action_space, action_std_init):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        # We define if the action space is continuous or a value choosen from a set of possible actions\n",
    "        self.has_continuous_action_space = has_continuous_action_space\n",
    "\n",
    "\n",
    "        if has_continuous_action_space:\n",
    "            self.action_dim = action_dim\n",
    "            self.action_var = torch.full((action_dim,), action_std_init * action_std_init).to(device)\n",
    "        # defining the actor\n",
    "        if has_continuous_action_space :\n",
    "            self.actor = nn.Sequential(\n",
    "                            nn.Linear(state_dim, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, action_dim),\n",
    "                        )\n",
    "        else:\n",
    "            self.actor = nn.Sequential(\n",
    "                            nn.Linear(state_dim, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, action_dim),\n",
    "                            nn.Softmax(dim=-1)\n",
    "                        )\n",
    "        # defining the critic\n",
    "        self.critic = nn.Sequential(\n",
    "                        nn.Linear(state_dim, 64),\n",
    "                        nn.Tanh(),\n",
    "                        nn.Linear(64, 64),\n",
    "                        nn.Tanh(),\n",
    "                        nn.Linear(64, 1)\n",
    "                    )\n",
    "\n",
    "    def set_action_std(self, new_action_std):\n",
    "        #We only calculate the action std if we have a continuous action space\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_var = torch.full((self.action_dim,), new_action_std * new_action_std).to(device)\n",
    "        else:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"WARNING : Calling ActorCritic::set_action_std() on discrete action space policy\")\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    def forward(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def act(self, state):\n",
    "        # if we have a continuous action space we sample from a multivariate normal distribution\n",
    "        # otherwise we calculate a categorical action spac\n",
    "        if self.has_continuous_action_space:\n",
    "            action_mean = self.actor(state)\n",
    "            cov_mat = torch.diag(self.action_var).unsqueeze(dim=0)\n",
    "            dist = MultivariateNormal(action_mean, cov_mat)\n",
    "        else:\n",
    "            action_probs = self.actor(state)\n",
    "            dist = Categorical(action_probs)\n",
    "\n",
    "        action = dist.sample()\n",
    "        action_logprob = dist.log_prob(action)\n",
    "\n",
    "        return action.detach(), action_logprob.detach()\n",
    "\n",
    "    def evaluate(self, state, action):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            action_mean = self.actor(state)\n",
    "\n",
    "            action_var = self.action_var.expand_as(action_mean)\n",
    "            cov_mat = torch.diag_embed(action_var).to(device)\n",
    "            dist = MultivariateNormal(action_mean, cov_mat)\n",
    "\n",
    "            # For Single Action Environments.\n",
    "            if self.action_dim == 1:\n",
    "                action = action.reshape(-1, self.action_dim)\n",
    "        else:\n",
    "            action_probs = self.actor(state)\n",
    "            dist = Categorical(action_probs)\n",
    "        action_logprobs = dist.log_prob(action)\n",
    "        dist_entropy = dist.entropy()\n",
    "        state_values = self.critic(state)\n",
    "\n",
    "        return action_logprobs, state_values, dist_entropy\n"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": [
    "##PPO"
   ],
   "metadata": {
    "id": "eKo891_Luri6"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ealjmWSObWdq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745690865396,
     "user_tz": -120,
     "elapsed": 18,
     "user": {
      "displayName": "Bjarne Thomzik",
      "userId": "06928226671254719565"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-04-27T23:16:27.229610Z",
     "start_time": "2025-04-27T23:16:27.186725Z"
    }
   },
   "source": [
    "class PPO:\n",
    "    def __init__(self, state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std_init=0.6):\n",
    "\n",
    "        self.has_continuous_action_space = has_continuous_action_space\n",
    "\n",
    "        if has_continuous_action_space:\n",
    "            self.action_std = action_std_init\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.eps_clip = eps_clip\n",
    "        self.K_epochs = K_epochs\n",
    "\n",
    "        self.buffer = RolloutBuffer()\n",
    "\n",
    "        self.policy = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
    "        self.optimizer = torch.optim.Adam([\n",
    "                        {'params': self.policy.actor.parameters(), 'lr': lr_actor},\n",
    "                        {'params': self.policy.critic.parameters(), 'lr': lr_critic}\n",
    "                    ])\n",
    "\n",
    "        self.policy_old = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "\n",
    "        self.MseLoss = nn.MSELoss()\n",
    "\n",
    "    def set_action_std(self, new_action_std):\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_std = new_action_std\n",
    "            self.policy.set_action_std(new_action_std)\n",
    "            self.policy_old.set_action_std(new_action_std)\n",
    "        else:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"WARNING : Calling PPO::set_action_std() on discrete action space policy\")\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    def decay_action_std(self, action_std_decay_rate, min_action_std):\n",
    "        print(\"--------------------------------------------------------------------------------------------\")\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_std = self.action_std - action_std_decay_rate\n",
    "            self.action_std = round(self.action_std, 4)\n",
    "            if (self.action_std <= min_action_std):\n",
    "                self.action_std = min_action_std\n",
    "                print(\"setting actor output action_std to min_action_std : \", self.action_std)\n",
    "            else:\n",
    "                print(\"setting actor output action_std to : \", self.action_std)\n",
    "            self.set_action_std(self.action_std)\n",
    "\n",
    "        else:\n",
    "            print(\"WARNING : Calling PPO::decay_action_std() on discrete action space policy\")\n",
    "        print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    def select_action(self, state):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            with torch.no_grad():\n",
    "                state = torch.FloatTensor(state).to(device)\n",
    "                action, action_logprob = self.policy_old.act(state)\n",
    "\n",
    "            self.buffer.states.append(state.cpu())\n",
    "            self.buffer.actions.append(action.cpu())\n",
    "            self.buffer.logprobs.append(action_logprob.cpu())\n",
    "\n",
    "            return action.detach().cpu().numpy().flatten()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                state = torch.FloatTensor(state).to(device)\n",
    "                action, action_logprob = self.policy_old.act(state)\n",
    "\n",
    "            self.buffer.states.append(state)\n",
    "            self.buffer.actions.append(action)\n",
    "            self.buffer.logprobs.append(action_logprob)\n",
    "\n",
    "            return action.item()\n",
    "\n",
    "    def update(self):\n",
    "        # Monte Carlo estimate of returns\n",
    "        rewards = []\n",
    "        discounted_reward = 0\n",
    "        for reward, is_terminal in zip(reversed(self.buffer.rewards), reversed(self.buffer.is_terminals)):\n",
    "            if is_terminal:\n",
    "                discounted_reward = 0\n",
    "            discounted_reward = reward + (self.gamma * discounted_reward)\n",
    "            rewards.insert(0, discounted_reward)\n",
    "\n",
    "        # Normalizing the rewards\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
    "        rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-7)\n",
    "\n",
    "        # convert list to tensor\n",
    "        old_states = torch.squeeze(torch.stack(self.buffer.states, dim=0)).detach().to(device)\n",
    "        old_actions = torch.squeeze(torch.stack(self.buffer.actions, dim=0)).detach().to(device)\n",
    "        old_logprobs = torch.squeeze(torch.stack(self.buffer.logprobs, dim=0)).detach().to(device)\n",
    "\n",
    "        # Optimize policy for K epochs\n",
    "        for _ in range(self.K_epochs):\n",
    "\n",
    "            # Evaluating old actions and values\n",
    "            logprobs, state_values, dist_entropy = self.policy.evaluate(old_states, old_actions)\n",
    "\n",
    "            # match state_values tensor dimensions with rewards tensor\n",
    "            state_values = torch.squeeze(state_values)\n",
    "\n",
    "            # Finding the ratio (pi_theta / pi_theta__old)\n",
    "            ratios = torch.exp(logprobs - old_logprobs.detach())\n",
    "\n",
    "            # Finding Surrogate Loss\n",
    "            advantages = rewards - state_values.detach()\n",
    "            surr1 = ratios * advantages\n",
    "            surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages\n",
    "\n",
    "            # final loss of clipped objective PPO\n",
    "            loss = -torch.min(surr1, surr2) + 0.5*self.MseLoss(state_values, rewards) - 0.01*dist_entropy\n",
    "\n",
    "            # take gradient step\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        # Copy new weights into old policy\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "\n",
    "        # clear buffer\n",
    "        self.buffer.clear()\n",
    "\n",
    "    def save(self, checkpoint_path):\n",
    "        torch.save(self.policy_old.state_dict(), checkpoint_path)\n",
    "\n",
    "    def load(self, checkpoint_path):\n",
    "        self.policy_old.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
    "        self.policy.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Helper Functions for the environments and rendering"
   ],
   "metadata": {
    "id": "xDcMPok6uvNR"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "K5_5pBVNgfv_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745690869320,
     "user_tz": -120,
     "elapsed": 5,
     "user": {
      "displayName": "Bjarne Thomzik",
      "userId": "06928226671254719565"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-04-27T23:16:27.276485Z",
     "start_time": "2025-04-27T23:16:27.262522Z"
    }
   },
   "source": [
    "#renders given frames with mediapy and shows a video\n",
    "def renderEnv(frames):\n",
    "  import mediapy as media\n",
    "  media.show_video(frames,fps=60//4)\n",
    "\n",
    "#plot for visualizing results\n",
    "def plotRewardandTime(avg_norm_reward,avg_length):\n",
    "  import matplotlib.pyplot as plt\n",
    "  x = np.linspace(0,len(avg_reward),len(avg_reward))\n",
    "\n",
    "  fig, axs = plt.subplots(1, 2,figsize=(9,3))\n",
    "\n",
    "  axs[0].plot(x, avg_norm_reward)\n",
    "  axs[0].set_title(\"avg_norm_reward\")\n",
    "\n",
    "  axs[1].plot(x, avg_length)\n",
    "  axs[1].set_title(\"avg_length\")\n",
    "  plt.show()"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1Pk0QoPX5t3p",
    "ExecuteTime": {
     "end_time": "2025-04-27T23:16:27.337322Z",
     "start_time": "2025-04-27T23:16:27.324356Z"
    }
   },
   "source": [
    "import gym\n",
    "\n",
    "#This environment wrapper is used to stop a run if mario is stuck on a pipe\n",
    "class DeadlockEnv(gym.Wrapper):\n",
    "    def __init__(self, env, threshold=10):\n",
    "        super().__init__(env)\n",
    "        self.last_x_pos = 0\n",
    "        self.count = 0\n",
    "        self.threshold = threshold\n",
    "        self.lifes = 3\n",
    "        self.stage = 1\n",
    "        self.world = 1\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        self.last_x_pos = 0\n",
    "        self.count = 0\n",
    "        return self.env.reset(**kwargs)\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, done, info = self.env.step(action)\n",
    "        x_pos = info['x_pos']\n",
    "\n",
    "        if x_pos <= self.last_x_pos:\n",
    "            self.count += 1\n",
    "        else:\n",
    "            self.count = 0\n",
    "            self.last_x_pos = x_pos\n",
    "\n",
    "        if info['life'] != self.lifes or info[\"stage\"] != self.stage or info[\"world\"] != self.world:\n",
    "            self.last_x_pos = x_pos\n",
    "            self.count = 0\n",
    "            self.lifes = info['life']\n",
    "            self.stage = info[\"stage\"]\n",
    "            self.world = info[\"world\"]\n",
    "\n",
    "        if self.count >= self.threshold:\n",
    "            reward = -15\n",
    "            done = True\n",
    "\n",
    "        return state, reward, done, info\n",
    "\n",
    "#skipframe wrapper\n",
    "class SkipFrame(gym.Wrapper):\n",
    "    def __init__(self, env, skip):\n",
    "        super().__init__(env)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        reward_out = 0\n",
    "        for i in range(self._skip):\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            reward_out += reward\n",
    "            if done:\n",
    "                break\n",
    "        reward_out /= max(1,i+1)\n",
    "\n",
    "        return obs, reward_out, done, info\n",
    "\n",
    "#downsample wrapper to reduce dimensionality\n",
    "def Downsample(ratio,state):\n",
    "  (oldh, oldw, oldc) = state.shape\n",
    "  newshape = (oldh//ratio, oldw//ratio, oldc)\n",
    "  frame = cv2.resize(state, (newshape[0], newshape[1]), interpolation=cv2.INTER_AREA)\n",
    "  return frame\n",
    "\n",
    "#small function to change rgb images to grayscale\n",
    "def GrayScale(state):\n",
    "  return cv2.cvtColor(state, cv2.COLOR_RGB2GRAY)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Training\n",
    "\n",
    "If you want to run this for more than an hour and really test how far your model gets, I would recommend to start a local runtime on your computer/laptop.\n",
    "Here is a link on how to create a local runtime: https://research.google.com/colaboratory/local-runtimes.html"
   ],
   "metadata": {
    "id": "aqeX3kGEyE45"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4WeQxPlZcq4_",
    "executionInfo": {
     "status": "error",
     "timestamp": 1745690888257,
     "user_tz": -120,
     "elapsed": 386,
     "user": {
      "displayName": "Bjarne Thomzik",
      "userId": "06928226671254719565"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "outputId": "2d2e9b97-e58f-4fe3-8b1a-34df9ae4bac1"
   },
   "source": [
    "from IPython.core.display import clear_output\n",
    "\n",
    "\n",
    "state_dim = 15360                     # state space dimension\n",
    "lr_actor = 0.0003                     # learning rate for actor network\n",
    "lr_critic = 0.001                     # learning rate for critic network\n",
    "gamma = 0.99                          # gamma discount\n",
    "K_epochs = 50                         # K value for the PPO-CLIP objective function\n",
    "eps_clip = 0.2                        # the epsilon clipping value\n",
    "has_continuous_action_space = False   # the mario environment doesn't have a continuous action space\n",
    "action_std = None                     # we don't change the action distribution\n",
    "frameskip = 4                         # the frameskip value of the environment\n",
    "down_sample_rate = 4                  # downsample rate. Calculated as: original_dimension/down_sample_rate\n",
    "frame_stack = 4                       # frame stacking value\n",
    "\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v1')  #the environment. v0 is with original background, v1 has the background removed\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)               #The Joypadspace sets the available actions. We use SIMPLE_MOVEMENT.\n",
    "env = SkipFrame(env, skip=frameskip)                  #Skipframewrapper to skip some frames\n",
    "env = DeadlockEnv(env,threshold=(60*2)//frameskip)                   #Deadlock environment wrapper to stop the game if mario is stuck at a pipe\n",
    "\n",
    "\n",
    "\n",
    "action_dim = env.action_space.n # action space dimension\n",
    "#state_dim = env.state_space.n  # Currently we flatten the input and therefore set the state_dim manually\n",
    "\n",
    "ppo_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "\n",
    "# track total training time\n",
    "start_time = datetime.now().replace(microsecond=0)\n",
    "print(\"Started training at (GMT) : \", start_time)\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "#some helper variables\n",
    "time_step = 0\n",
    "max_training_epochs = 10000\n",
    "max_ep_len = 10000\n",
    "update_timestep = max_ep_len\n",
    "\n",
    "# We mount the google drive to save and load PPO states.\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "\n",
    "# If an agent is saved you can uncomment the following line to load the weights.\n",
    "#ppo_agent.load(\"/content/gdrive/My Drive/ppo.save\")\n",
    "\n",
    "avg_reward_temp = []\n",
    "avg_length_temp = []\n",
    "avg_norm_reward_temp = []\n",
    "avg_reward = []\n",
    "avg_length = []\n",
    "avg_norm_reward = []\n",
    "updates = 0\n",
    "\n",
    "episode_list = []\n",
    "\n",
    "tbar = tqdm(range(1,max_training_epochs))\n",
    "for i in tbar:\n",
    "    # first we reset the state\n",
    "    state = env.reset()\n",
    "    current_ep_reward = 0\n",
    "    # as we stack some frames, we create a buffer with empty frames for the first inputs\n",
    "    states_buffer = [np.zeros((3840,)) for _ in range(3)]\n",
    "    frames = []\n",
    "    # the collection loop\n",
    "    for t in range(1, max_ep_len):\n",
    "        # Downsampling the environment\n",
    "        in_state = GrayScale(Downsample(down_sample_rate,state.copy())).flatten()\n",
    "\n",
    "        # creating the new stack for the current frame\n",
    "        states_buffer.append(in_state/255)\n",
    "        states_buffer = states_buffer[-frame_stack:]\n",
    "\n",
    "        # selecting an action\n",
    "        action = ppo_agent.select_action(np.asarray(states_buffer).flatten())\n",
    "        #print(np.asarray(states_buffer).flatten().min(),np.asarray(states_buffer).flatten().max())\n",
    "\n",
    "        # performing the action and receiving the information from the environments\n",
    "        state, reward, done, info = env.step(action)\n",
    "\n",
    "        # Every 10 epochs we render the environments and therefore save the state\n",
    "        if not done:\n",
    "            frames.append(state.copy())\n",
    "\n",
    "        # The PPO agent needs the reward and the done state manually, as we could modify it.\n",
    "        ppo_agent.buffer.rewards.append(reward)\n",
    "        ppo_agent.buffer.is_terminals.append(done)\n",
    "\n",
    "        time_step +=1\n",
    "        current_ep_reward += reward\n",
    "\n",
    "        # every update_steps (2048) we update the algorithm\n",
    "        #if time_step % update_steps == 0:\n",
    "\n",
    "\n",
    "        # if the run is done we break the loop\n",
    "        if done:\n",
    "            break\n",
    "    if len(frames) > 0:\n",
    "      episode_list.append((current_ep_reward,frames))\n",
    "\n",
    "\n",
    "\n",
    "    # We collect information every run and write them to the console\n",
    "    avg_reward_temp.append(current_ep_reward)\n",
    "    avg_length_temp.append(t)\n",
    "    tbar.set_description(\"timestep: \" + str(time_step) + \" updates: \"+str(updates)+\" reward: \"+str(np.asarray(avg_norm_reward_temp[-50:]).mean()))\n",
    "    avg_norm_reward_temp.append(current_ep_reward/max(1,t))\n",
    "\n",
    "    # Every 10 epochs we render the current environment\n",
    "    if i % 10 == 0:\n",
    "      ppo_agent.update()\n",
    "      updates += 1\n",
    "      avg_reward.append(np.median(avg_reward_temp))\n",
    "      avg_length.append(np.median(avg_length_temp))\n",
    "      avg_norm_reward.append(np.median(avg_norm_reward_temp))\n",
    "\n",
    "      if len(episode_list) > 0:\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        episode_list.sort(key=lambda x: x[0]) # we sort by the received reward and pick the best run to visualize\n",
    "\n",
    "        print(\"--------------------------------\")\n",
    "        print(\"Epoch\",i,\"done:\")\n",
    "        print(\"Update iterations:\",updates)\n",
    "        print(\"Statistics:\")\n",
    "        print(\"\")\n",
    "        print(\"Reward of best episode:\",episode_list[-1][0])\n",
    "        print(\"Length of best episode:\",len(episode_list[-1][1]))\n",
    "        print(\"\")\n",
    "        print(\"Average total reward:\",np.asarray(avg_reward[-50:]).mean())\n",
    "        print(\"Average normalized reward:\",np.asarray(avg_norm_reward[-50:]).mean())\n",
    "        print(\"Average length:\",np.asarray(avg_length[-50:]).mean())\n",
    "        print(\"--------------------------------\")\n",
    "        plotRewardandTime(avg_norm_reward,avg_length)\n",
    "\n",
    "        #renderEnv(episode_list[-1][1])\n",
    "\n",
    "        # Save best run as mp4\n",
    "        import mediapy as media\n",
    "        from IPython.display import Video, display\n",
    "\n",
    "        frames_to_save = episode_list[-1][1]\n",
    "        filename = f\"best_run_epoch_{i}.mp4\"\n",
    "\n",
    "        if frames_to_save:\n",
    "            media.write_video(filename, frames_to_save, fps=60//4)\n",
    "            video_display = Video(filename)\n",
    "            display(video_display)\n",
    "        else:\n",
    "            print(\"No frames to save or display.\")\n",
    "\n",
    "\n",
    "        episode_list = []\n",
    "\n",
    "        #ppo_agent.save(\"/content/gdrive/My Drive/ppo.save\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "env.close()"
   ],
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 900x300 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Video object>"
      ],
      "text/html": [
       "<video src=\"best_run_epoch_70.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "timestep: 16100 updates: 7 reward: 1.0755301950976808:   1%|          | 78/9999 [02:47<5:54:12,  2.14s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[36], line 79\u001B[0m\n\u001B[0;32m     75\u001B[0m action \u001B[38;5;241m=\u001B[39m ppo_agent\u001B[38;5;241m.\u001B[39mselect_action(np\u001B[38;5;241m.\u001B[39masarray(states_buffer)\u001B[38;5;241m.\u001B[39mflatten())\n\u001B[0;32m     76\u001B[0m \u001B[38;5;66;03m#print(np.asarray(states_buffer).flatten().min(),np.asarray(states_buffer).flatten().max())\u001B[39;00m\n\u001B[0;32m     77\u001B[0m \n\u001B[0;32m     78\u001B[0m \u001B[38;5;66;03m# performing the action and receiving the information from the environments\u001B[39;00m\n\u001B[1;32m---> 79\u001B[0m state, reward, done, info \u001B[38;5;241m=\u001B[39m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;66;03m# Every 10 epochs we render the environments and therefore save the state\u001B[39;00m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m done:\n",
      "Cell \u001B[1;32mIn[32], line 20\u001B[0m, in \u001B[0;36mDeadlockEnv.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, action):\n\u001B[1;32m---> 20\u001B[0m     state, reward, done, info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m     x_pos \u001B[38;5;241m=\u001B[39m info[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx_pos\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     23\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m x_pos \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_x_pos:\n",
      "Cell \u001B[1;32mIn[32], line 51\u001B[0m, in \u001B[0;36mSkipFrame.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     49\u001B[0m reward_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_skip):\n\u001B[1;32m---> 51\u001B[0m     obs, reward, done, info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     52\u001B[0m     reward_out \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m reward\n\u001B[0;32m     53\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m done:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\mario\\lib\\site-packages\\nes_py\\wrappers\\joypad_space.py:74\u001B[0m, in \u001B[0;36mJoypadSpace.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     59\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;124;03mTake a step using the given action.\u001B[39;00m\n\u001B[0;32m     61\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     71\u001B[0m \n\u001B[0;32m     72\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;66;03m# take the step and record the output\u001B[39;00m\n\u001B[1;32m---> 74\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_action_map\u001B[49m\u001B[43m[\u001B[49m\u001B[43maction\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\mario\\lib\\site-packages\\gym\\wrappers\\time_limit.py:49\u001B[0m, in \u001B[0;36mTimeLimit.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, action):\n\u001B[0;32m     39\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \n\u001B[0;32m     41\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;124;03m        \"TimeLimit.truncated\"=False if the environment terminated\u001B[39;00m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 49\u001B[0m     observation, reward, done, info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_elapsed_steps \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_elapsed_steps \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_max_episode_steps:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\mario\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py:37\u001B[0m, in \u001B[0;36mOrderEnforcing.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_reset:\n\u001B[0;32m     36\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ResetNeeded(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot call env.step() before calling env.reset()\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 37\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\mario\\lib\\site-packages\\gym\\wrappers\\env_checker.py:41\u001B[0m, in \u001B[0;36mPassiveEnvChecker.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     39\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m passive_env_step_check(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menv, action)\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 41\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\mario\\lib\\site-packages\\nes_py\\nes_env.py:300\u001B[0m, in \u001B[0;36mNESEnv.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m    298\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrollers[\u001B[38;5;241m0\u001B[39m][:] \u001B[38;5;241m=\u001B[39m action\n\u001B[0;32m    299\u001B[0m \u001B[38;5;66;03m# pass the action to the emulator as an unsigned byte\u001B[39;00m\n\u001B[1;32m--> 300\u001B[0m \u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mStep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_env\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    301\u001B[0m \u001B[38;5;66;03m# get the reward for this step\u001B[39;00m\n\u001B[0;32m    302\u001B[0m reward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_reward())\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1DjgoJPE0IIPGf_t0f9Trgrpz4wRMPIJt",
     "timestamp": 1745688511642
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
